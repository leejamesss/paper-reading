
## 主要内容概括
这篇文章的主要内容是：
- **大型语言模型的自动思维链提示**：这篇文章提出了一种方法，可以利用大型语言模型（LLMs）的多步推理能力，通过自动生成示例来提示LLMs产生中间推理步骤。这种方法叫做Auto-CoT，它通过对问题进行聚类和采样，以及使用零样本推理生成推理链，来构造示例。实验结果表明，Auto-CoT在十个公开的推理任务数据集上，都能达到或超过手工设计示例的效果。
- **思维链提示的两种范式**：思维链提示（CoT prompting）是一种梯度无关的技术，可以引导LLMs产生一系列连贯的中间推理步骤，从而得到问题的最终答案。思维链提示有两种主要的范式：一种是使用一个简单的提示语，如“让我们一步一步地思考”，来促进LLMs进行分步思考（Zero-Shot-CoT）；另一种是使用少量手工编写的示例，每个示例包含一个问题和一个推理链（Manual-CoT）。实践中，Manual-CoT有更强的性能，但是需要人工设计任务相关的示例。
- **自动思维链提示的挑战和方法**：为了消除人工设计示例的需求，作者提出了Auto-CoT方法来自动构造示例。Auto-CoT包括两个主要步骤：（1）问题聚类：将给定数据集的问题分成几个簇；（2）示例采样：从每个簇中选择一个代表性的问题，并使用Zero-Shot-CoT和简单的启发式规则生成其推理链。作者发现，采样问题时，多样性比相似性更重要，因为多样性可以减轻由于零样本推理错误导致的误导效应。


**代码链接：https://github.com/amazon-research/auto-cot**


## 问题与思考


### 1-Auto-CoT和Manual-CoT有什么区别？
- Auto-CoT和Manual-CoT是两种不同的思维链提示范式。它们都可以引导大型语言模型（LLMs）产生一系列连贯的中间推理步骤，从而得到问题的最终答案。

- Manual-CoT使用少量手工编写的示例，每个示例包含一个问题和一个推理链。这种方法需要人工设计任务相关的示例，但是实践中它有更强的性能。

- 相比之下，Auto-CoT是一种自动构造示例的方法。它通过对问题进行聚类和采样，以及使用零样本推理生成推理链，来构造示例。这种方法消除了人工设计示例的需求，并且在十个公开的推理任务数据集上都能达到或超过手工设计示例的效果。

- Auto-CoT和Manual-CoT都是思维链提示范式，但它们在构造示例方面有所不同。Manual-CoT需要人工设计任务相关的示例，而Auto-CoT则可以自动构造示例。




### 2-作者使用了哪些数据集来测试?

- **BoolQ**：一个布尔型问题回答数据集，包含2,760个问题和答案，以及与问题相关的维基百科段落。
- **COPA**：一个因果推理数据集，包含1,000个问题和答案，每个问题要求从两个选项中选择一个正确的因果关系。
- **HellaSwag**：一个常识推理数据集，包含39,905个问题和答案，每个问题要求从四个选项中选择一个正确的事件续写。
- **LAMA**：一个知识库问答数据集，包含43,757个问题和答案，每个问题要求从知识库中填充一个缺失的实体或属性。
- **MC-TACO**：一个时序常识推理数据集，包含7,762个问题和答案，每个问题要求从四个选项中选择一个正确的时间跨度。
- **MultiRC**：一个多选阅读理解数据集，包含5,467个段落、21,142个问题和48,579个答案，每个问题要求从多个选项中选择所有正确的答案。
- **PIQA**：一个物理常识推理数据集，包含16,113个问题和答案，每个问题要求从两个选项中选择一个正确的物理操作。
- **ReCoRD**：一个阅读理解数据集，包含10,101篇新闻文章、120,591个问题和302,932个答案，每个问题要求从文章中提取一个或多个实体作为答案。
- **SocialIQA**：一个社会常识推理数据集，包含37,905个问题和答案，每个问题要求从三个选项中选择一个正确的社会行为。
- **WSC**：一个代词消歧数据集，包含273个句子和代词，每个句子要求从两个候选名词中选择一个正确的代词指代。

**PS.数据集补充说明**
- BoolQ数据集包含了一些自然产生的是/非问题，这些问题需要复杂的非事实性信息和类似于蕴含的推理来解决。
- HellaSwag数据集则是一个新的挑战性数据集，它的问题对人类来说非常简单（>95%的准确率），但对于最先进的模型来说却很困难（<48%）。


```
(HellaSwag介绍)
HellaSwag是一个常识推理数据集，它包含了39,905个问题和答案，每个问题要求从四个选项中选择一个正确的事件续写。

eg.
问题：在一家餐厅，一位顾客点了一杯咖啡。然后，服务员...

选项：
A. 把咖啡倒在了顾客的头上。
B. 把咖啡端到了顾客的桌子上。
C. 把咖啡倒进了自己的口袋里。
D. 把咖啡倒进了鱼缸里。

正确答案：B. 把咖啡端到了顾客的桌子上。

这个例子展示了HellaSwag数据集中的一个典型问题。它要求模型根据常识推理出最可能发生的事件续写。
```


### 3-Auto-CoT在数据集的表现如何？

- **算术推理**：Auto-CoT在MultiArith, GSM8K, AddSub, AQuA, SingleEq和SVAMP这六个算术推理数据集上，都超过了手工设计示例的Manual-CoT的准确率，达到了84.8%到92.0%的范围。
- **常识推理**：Auto-CoT在CSQA和StrategyQA这两个常识推理数据集上，与Manual-CoT的准确率相当，分别为74.4%和65.4%。
- **符号推理**：Auto-CoT在Last Letter Concatenation和Coin Flip这两个符号推理数据集上，也与Manual-CoT的准确率相当，分别为59.7%和99.9%。

Auto-CoT在十个公开的推理任务数据集上，都能达到或超过手工设计示例的Manual-CoT的表现。这说明Auto-CoT可以利用大型语言模型（LLMs）的多步推理能力，通过自动生成示例来提示LLMs产生中间推理步骤。




