![image](https://github.com/leejamesss/paper-reading/assets/117844938/cce72ccd-c98f-4493-968b-d29e05359f7f)
![image](https://github.com/leejamesss/paper-reading/assets/117844938/a94fe8e4-dad3-4134-8ef9-78468b4dc4e1)
![image](https://github.com/leejamesss/paper-reading/assets/117844938/e466ea61-7182-4125-8d5b-2ec8e2a74f23)
![image](https://github.com/leejamesss/paper-reading/assets/117844938/0edf25ef-6ebe-4caf-80ba-905d0cd6be08)




# 1. 这篇论文的主要贡献是什么？
- 提出了一种新的参数高效调整（PETuning）方法，叫做**后期提示调整（LPT）**，它结合了**后期提示**和**实例感知提示**，可以提高传统的提示调整方法的性能和效率。
- 通过实验分析，发现传统的提示调整方法性能不佳的原因是从标签信号到输入提示的传播路径过长，导致任务相关信息在冻结模型中传播时丢失。
- 通过在不同的层次插入软提示，发现适当缩短传播路径可以提高性能，但过度缩短会降低提示对模型输出的影响力。因此，选择一个合适的中间层作为提示层，既可以接收更多的任务相关信息，又可以保持足够的影响力。
- 通过引入一个提示生成器，利用提示层之前的隐藏状态为每个实例生成一个独立的软提示，进一步提高性能和利用上下文信息。
- 在全数据和少量数据的情况下，在10个文本分类任务和3个预训练模型上进行了广泛的实验，证明了LPT可以达到与全模型调整和其他PETuning方法相当甚至更好的性能，同时具有更快的训练速度和更低的内存消耗。
# 2. 这个贡献重要吗？为什么？

- 提出了一种新的参数高效调整（PETuning）方法，叫做**后期提示调整（LPT）**，它结合了**后期提示**和**实例感知提示**，可以提高传统的提示调整方法的性能和效率。
- 通过实验分析，发现传统的提示调整方法性能不佳的原因是从标签信号到输入提示的传播路径过长，导致任务相关信息在冻结模型中传播时丢失。
- 通过在不同的层次插入软提示，发现适当缩短传播路径可以提高性能，但过度缩短会降低提示对模型输出的影响力。因此，选择一个合适的中间层作为提示层，既可以接收更多的任务相关信息，又可以保持足够的影响力。
- 通过引入一个提示生成器，利用提示层之前的隐藏状态为每个实例生成一个独立的软提示，进一步提高性能和利用上下文信息。
- 在全数据和少量数据的情况下，在10个文本分类任务和3个预训练模型上进行了广泛的实验，证明了LPT可以达到与全模型调整和其他PETuning方法相当甚至更好的性能，同时具有更快的训练速度和更低的内存消耗。

本文的贡献是重要的，因为它为利用预训练模型解决下游任务提供了一种简单而有效的方法，既可以节省参数和计算资源，又可以保证高质量的结果。本文也为后续研究提供了一些有价值的分析和启示。



# 3. 这篇论文的局限是什么？

- **实验的可复现性**：本文没有提供实验的代码和数据集，也没有详细说明实验的设置和超参数，这可能会影响其他研究者复现和验证本文的结果。
- **实验的广泛性**：本文只在10个文本分类任务和3个预训练模型上进行了实验，没有涵盖其他类型的下游任务和模型，例如自然语言生成、知识图谱、对话系统等，也没有考虑不同语言和领域的影响，这可能会限制本文方法的泛化能力和适用范围。
- **理论的深入性**：本文没有给出LPT方法的理论分析和证明，也没有探讨LPT方法与其他PETuning方法之间的联系和区别，这可能会影响本文方法的理解和推广。



# 4. 根据这篇文章的结果，你得到什么启发？

- **后期提示调整（LPT）**：这是一种新的参数高效调整（PETuning）方法，它结合了**后期提示**和**实例感知提示**，可以提高传统的提示调整方法的性能和效率。LPT通过在不同的层次插入软提示，发现适当缩短传播路径可以提高性能，但过度缩短会降低提示对模型输出的影响力。因此，选择一个合适的中间层作为提示层，既可以接收更多的任务相关信息，又可以保持足够的影响力。LPT还通过引入一个提示生成器，利用提示层之前的隐藏状态为每个实例生成一个独立的软提示，进一步提高性能和利用上下文信息。
- **传统提示调整方法的不足**：通过实验分析，发现传统的提示调整方法性能不佳的原因是从标签信号到输入提示的传播路径过长，导致任务相关信息在冻结模型中传播时丢失。而且，传统的提示调整方法需要修改原始输入并使用人工模板和标签词，这可能会影响模型的泛化能力和适应性。
- **LPT与其他PETuning方法的比较**：通过在全数据和少量数据的情况下，在10个文本分类任务和3个预训练模型上进行了广泛的实验，证明了LPT可以达到与全模型调整和其他PETuning方法相当甚至更好的性能，同时具有更快的训练速度和更低的内存消耗。特别是在只有100个训练样本的情况下，LPT比全模型调整提高了5个百分点，比Adapter提高了7.1个百分点。



# 5. 这篇论文的研究假设是什么？这些假设是否合理、局限或过于简化？
我认为它的一些研究假设是：

- **传统的提示调整方法性能不佳的原因是从标签信号到输入提示的传播路径过长**，导致任务相关信息在冻结模型中传播时丢失。
- **适当缩短传播路径可以提高性能，但过度缩短会降低提示对模型输出的影响力**。因此，选择一个合适的中间层作为提示层，既可以接收更多的任务相关信息，又可以保持足够的影响力。
- **引入一个提示生成器，利用提示层之前的隐藏状态为每个实例生成一个独立的软提示**，进一步提高性能和利用上下文信息。

我认为这些假设是合理的，但也有一些局限或过于简化的地方：

- **假设一**：这个假设没有考虑其他可能影响性能的因素，例如输入提示的长度、模板、标签词等。也没有给出从标签信号到输入提示的传播路径过长会导致多少信息损失的量化分析。
- **假设二**：这个假设没有给出如何确定最佳的提示层的方法或标准。也没有探讨不同任务和模型对于提示层选择的影响和差异。
- **假设三**：这个假设没有比较不同类型和结构的提示生成器对于性能和效率的影响。也没有分析提示生成器是否会引入额外的噪声或偏差。


# 6. 基于这篇论文的可能应用有哪些？


- **利用预训练模型解决下游任务**：本文提出的LPT方法是一种简单而有效的参数高效调整方法，可以在不改变预训练模型的结构和参数的情况下，通过调整一个后期提示来适应不同的下游任务，例如文本分类、自然语言推理、情感分析等。
- **提高模型部署和推理的效率**：本文的LPT方法具有更快的训练速度和更低的内存消耗，相比于全模型调整和其他参数高效调整方法，可以节省更多的计算资源和存储空间。此外，LPT方法也可以实现混合任务推理，即在同一个预训练模型上同时运行多个下游任务，而无需为每个任务单独加载一个模型。
- **探索提示调整方法的理论和实践**：本文通过实验分析发现了传统的提示调整方法性能不佳的原因，并提出了后期提示和实例感知提示的概念，为提示调整方法的理解和改进提供了一些有价值的见解和启示。本文也为后续研究提供了一些可能的方向，例如如何确定最佳的提示层、如何设计更优秀的提示生成器、如何将LPT方法扩展到其他类型的下游任务和预训练模型等。



# 7. 在该文基础上，有些工作可以继续延伸下去？如何延伸？

- **探索不同的提示生成器**：本文使用了两种简单的提示生成器，即NPG和PPG，来利用提示层之前的隐藏状态为每个实例生成一个独立的软提示。但是，这些提示生成器可能没有充分利用隐藏状态的信息，也没有考虑不同任务和模型的特点。因此，可以尝试设计更复杂和更灵活的提示生成器，例如使用注意力机制、变分自编码器、生成对抗网络等，来提高提示的质量和多样性。
- **扩展到其他类型的下游任务和预训练模型**：本文只在文本分类任务和三种预训练模型上进行了实验，没有涵盖其他类型的下游任务和模型，例如自然语言生成、知识图谱、对话系统等，也没有考虑不同语言和领域的影响。因此，可以探索LPT在其他场景下的适用性和泛化能力，以及如何根据不同任务和模型的需求调整提示层的位置、长度和结构等。
- **分析LPT与其他PETuning方法之间的联系和区别**：本文没有给出LPT方法的理论分析和证明，也没有深入探讨LPT方法与其他PETuning方法之间的联系和区别，例如LPT与Adapter、BitFit、LoRA等方法在参数效率、性能、收敛速度等方面有什么优劣势，以及LPT与其他提示调整方法在提示设计、优化策略、任务适应性等方面有什么异同。因此，可以从理论和实践两个角度对LPT进行更深入的分析和比较。



# 8. 这篇论文中，哪些是你还没明白的地方？


- **提示调整方法的原理和优势**：提示调整方法是一种在预训练模型的基础上，通过调整模型的输入提示来完成特定任务的方法。提示调整方法的优点是可以在不改变模型结构和参数的情况下快速适应新任务，而且可以节省参数和计算资源，方便模型部署和推理。
- **后期提示和实例感知提示的概念和作用**：后期提示是指将提示插入到预训练模型的中间层，而不是输入层或所有层。后期提示可以缩短从标签信号到输入提示的传播路径，从而提高性能和收敛速度。实例感知提示是指利用一个提示生成器，根据每个输入实例的隐藏状态生成一个独立的软提示，从而提高性能和利用上下文信息。
- **LPT方法的实现细节和实验设置**：LPT方法使用了两种不同的提示生成器，即朴素提示生成器（NPG）和池化提示生成器（PPG），来生成后期提示和实例感知提示。LPT方法还探索了如何确定最佳的提示层，即将提示插入到预训练模型的哪一层。LPT方法在全数据和少量数据的情况下，在10个文本分类任务和3个预训练模型上进行了广泛的实验，与其他参数高效调整方法进行了比较。
- **LPT方法的理论分析和证明**：LPT方法没有给出其性能和效率的理论分析和证明，也没有深入探讨其与其他参数高效调整方法之间的联系和区别。这些方面可能需要更多的研究和证据来支持。


# 9. 还有什么其他相关的论文？它们之间有什么关系？
有一些其他相关的论文。例如，有一篇名为“LPT: Long-tailed Prompt Tuning for Image Classification”的论文，它提出了一种有效的长尾提示调整（LPT）方法，用于长尾分类任务。LPT将几个可训练的提示引入到冻结的预训练模型中，以将其适应长尾数据。这些提示分为两组：1）共享提示，用于整个长尾数据集，以学习通用特征并将预训练模型适应目标长尾域；2）组特定提示，用于收集具有相似特征的样本的组特定特征，并赋予预训练模型细粒度区分能力。然后设计了一个两阶段训练范式来学习这些提示。在第一阶段，我们通过常规监督提示调整来训练共享提示，以将预训练模型适应所需的长尾域。在第二阶段，我们使用学习到的共享提示作为查询，从组特定提示集中为一组相似样本选择一个最佳匹配的小集合，以挖掘这些相似样本的公共特征，然后使用双重采样策略和非对称高斯云对数损失优化这些提示。仅通过微调几个提示而固定预训练模型，LPT可以通过存储几个提示来减少训练成本和部署成本，并享受预训练模型的强大泛化能力。实验表明，在各种长尾基准上，仅使用~1.1％额外的可训练参数，LPT实现了与先前整个模型微调方法相当或更高的性能，并且对域移动更具鲁棒性。

这篇论文与其他关于参数高效调整（PETuning）方法的论文有关系。PETuning方法旨在利用预训练模型解决下游任务，同时节省参数和计算资源。LPT是一种PETuning方法，它通过引入后期提示和实例感知提示来提高性能和效率。



# 10. 基于这篇论文的思想，若要做一个项目，能否用两句话描述一下这个项目的大致思想？

- 这个项目的目的是利用预训练模型（PTM）解决下游任务，同时提高性能和效率。它的核心思想是在PTM的中间层插入一个后期提示（late prompt），并用一个提示生成器（prompt generator）为每个输入实例生成一个独立的软提示（instance-aware prompt）。
- 这个项目的优势是可以在不改变PTM的结构和参数的情况下，通过调整一个后期提示来适应不同的下游任务，例如文本分类、自然语言推理、情感分析等。它还可以节省参数和计算资源，加快训练速度和降低内存消耗。







# 疑难解答
## 什么是后期提示调整（LPT）?
后期提示调整（LPT）是一种新的参数高效调整（PETuning）方法，它结合了后期提示和实例感知提示，可以提高传统的提示调整方法的性能和效率。LPT通过在不同的层次插入软提示，发现适当缩短传播路径可以提高性能，但过度缩短会降低提示对模型输出的影响力。因此，选择一个合适的中间层作为提示层，既可以接收更多的任务相关信息，又可以保持足够的影响力。LPT还通过引入一个提示生成器，利用提示层之前的隐藏状态为每个实例生成一个独立的软提示，进一步提高性能和利用上下文信息。在全数据和少量数据的情况下，在10个文本分类任务和3个预训练模型上进行了广泛的实验，证明了LPT可以达到与全模型调整和其他PETuning方法相当甚至更好的性能，同时具有更快的训练速度和更低的内存消耗。

## 什么是传统的提示调整方法?
传统的提示调整方法是指在预训练模型的基础上，通过调整模型的输入提示来完成特定任务。这种方法通常包括两个步骤：首先，通过在输入文本前面添加一个固定的提示来引导模型的预测；其次，通过调整提示中的参数来优化模型的性能。这种方法的优点是可以在不改变模型结构和参数的情况下快速适应新任务，但缺点是性能不如全模型调整。

## 这篇论文的实验结果如何？

- **在全数据场景中**：LPT方法在全数据场景中的表现与AdapterDrop相当，尤其是LPT w/ MPPG和LPT w/ APPG。但它们的可调参数数量仅为AdapterDrop的三分之一。
- **在少量数据场景中**：LPT方法在少量数据场景中表现出色。特别是当训练集仅有100个样本时，LPT w/ NPG比模型调整高出5个百分点，比Adapter高出7.1个百分点。这表明我们的方法在训练数据非常稀缺时具有更好的泛化性能。
- **在训练速度和内存消耗方面**：LPT方法具有更快的训练速度和更低的内存消耗。与全模型调整相比，LPT w/ NPG在RoBERTaLARGE上的训练速度快2.0倍，内存消耗降低了56.6%。




