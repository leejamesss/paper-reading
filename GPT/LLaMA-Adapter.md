
# 主要内容

- **LLaMA-Adapter**：一种高效的适配方法，可以将LLaMA转化为一个能够根据指令生成响应的语言模型。只需要1.2M个可学习的参数和一个小时的训练，就可以有效地微调LLaMA，并且与全微调的7B参数的Alpaca相比具有优越的效率。
- **零初始化注意力**：为了提高训练的稳定性和最终的性能，我们提出了一种零初始化注意力机制，可以自适应地将指令信号注入到LLaMA中，同时有效地保留了LLaMA的预训练生成知识。
- **多模态推理**：我们的方法不仅限于文本指令，还可以扩展到图像条件下的多模态推理，在ScienceQA基准上表现出竞争性的性能。


代码链接：https://github.com/ZrrSkywalker/LLaMA-Adapter


# LLaMa介绍

## LLaMa是什么
LLaMA（Large Language Model Meta AI）是一种大型语言模型（LLMs），由Meta AI于2023年2月发布。在LLaMa的第一个版本中，训练了四种模型大小：7、13、33和65亿个参数。它旨在帮助研究人员在人工智能的这个子领域推进他们的工作。

## LLaMa应用场景
LLaMA（Large Language Model Meta AI）是一种大型语言模型，它具有多种应用场景。例如，它可以生成创造性文本，解决数学定理，预测蛋白质结构，回答阅读理解问题等。作为一种基础模型，LLaMA被设计成多功能的，可以应用于许多不同的用例，而不是针对特定任务设计的微调模型1。此外，Meta公司还发布了LLaMA 2，它包括7B、13B和70B模型，并且在更多令牌上进行了训练。这些模型不仅进一步加速了大型语言模型的研究工作，还使企业能够构建自己的生成性人工智能应用程序。

## LLaMa的性能

- **高效的适配**：这个模型只需要1.2M个可学习的参数和一个小时的训练，就可以将LLaMA转化为一个能够根据指令生成响应的语言模型。相比于全微调的7B参数的Alpaca，这个模型具有优越的效率。
- **零初始化注意力**：为了提高训练的稳定性和最终的性能，这个模型提出了一种零初始化注意力机制，可以自适应地将指令信号注入到LLaMA中，同时有效地保留了LLaMA的预训练生成知识。
- **多模态推理**：这个模型不仅限于文本指令，还可以扩展到图像条件下的多模态推理，在ScienceQA基准上表现出竞争性的性能。





# LLaMA-Adapter

## 介绍
LLaMA-Adapter是一种轻量级的适配方法，用于高效地微调LLaMA，使其成为一个能够根据指令生成响应的语言模型。它只需要1.2M个可学习的参数和一个小时的训练，就可以有效地微调LLaMA，并且与全微调的7B参数的Alpaca相比具有优越的效率。

## 机制
LLaMA-Adapter采用了一组可学习的适配提示，并在更高的变压器层中将它们添加到输入文本标记中。这些提示学会了如何自适应地将新指令（条件）注入到LLaMA中。为了避免在早期训练阶段适配提示带来的噪声，我们修改了插入层处的香草注意力机制，使其成为零初始化注意力，具有可学习的门控因子。通过零向量初始化，门控可以首先保留LLaMA中原有的知识，并在训练过程中逐渐合并指令信号。这有助于在微调过程中稳定学习，并更好地提高最终模型的指令跟随能力。

## 特征
- **1.2M参数**：我们冻结预训练的LLaMA，只在顶部学习1.2M个参数的适配提示。然而，这揭示了与7B Alpaca相当的指令跟随能力。
- **一小时微调**：由于轻量级参数和我们的零初始化门控，LLaMA-Adapter的收敛成本不到8个A100 GPU上的一个小时，比Alpaca快三倍。
- **插入专业知识**：对于不同的场景，可以灵活地插入各自的适配器并赋予LLaMA不同的专业知识。因此，在每个上下文中存储1.2M适配器就足够了，而不是完整复制7B模型。
- **多模态条件**：除了文本指令外，LLaMA-Adapter还可以扩展到图像输入以进行多模态推理。通过简单地将图像标记添加到适配提示中，LLaMA-Adapter在ScienceQA基准测试中表现出优越的推理能力。










# 疑难解答

## 零初始化注意力
零初始化注意力是一种注意力机制，它可以自适应地将指令信号注入到LLaMA中，同时有效地保留了LLaMA的预训练生成知识。这种机制通过使用一个可学习的门控因子来控制注意力分数，从而在训练的早期阶段避免了由于随机初始化而引入的干扰。这种机制的目的是在保持训练稳定性和最终性能的同时，将新的指令信号注入到模型中。

## 门控因子
门控因子是一种可学习的参数，用于控制注意力分数中适配提示的重要性。它通过乘以适配提示的注意力分数来实现这一点。在训练的早期阶段，门控因子被初始化为零，这意味着适配提示对模型的输出没有影响。随着训练的进行，门控因子的值会逐渐增加，从而允许适配提示对模型的输出产生更大的影响。这种机制可以有效地避免在训练早期由于随机初始化而引入的干扰，从而提高模型的训练稳定性和最终性能。

