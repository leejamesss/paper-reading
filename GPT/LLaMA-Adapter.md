
# 主要内容

- **LLaMA-Adapter**：一种高效的适配方法，可以将LLaMA转化为一个能够根据指令生成响应的语言模型。只需要1.2M个可学习的参数和一个小时的训练，就可以有效地微调LLaMA，并且与全微调的7B参数的Alpaca相比具有优越的效率。
- **零初始化注意力**：为了提高训练的稳定性和最终的性能，我们提出了一种零初始化注意力机制，可以自适应地将指令信号注入到LLaMA中，同时有效地保留了LLaMA的预训练生成知识。
- **多模态推理**：我们的方法不仅限于文本指令，还可以扩展到图像条件下的多模态推理，在ScienceQA基准上表现出竞争性的性能。


代码链接：https://github.com/ZrrSkywalker/LLaMA-Adapter

# 文章局限性

- **数据量的依赖**：这个模型需要大量的指令-输出数据来进行微调，而这些数据的质量和数量可能会影响模型的性能和泛化能力。目前，这个模型使用了Alpaca-52K数据集，但是这个数据集是由GPT-3.5自动生成的，并没有经过人工审核和筛选。因此，这个数据集可能存在一些噪声和错误，导致模型学习到不准确或不一致的指令知识。
- **适配提示的设计**：这个模型使用了一组可学习的适配提示来注入新的指令信号到LLaMA中，但是这些提示的长度和位置可能会影响模型的效果。目前，这个模型将10个长度的提示插入到最后30层变压器中，但是这个设置并没有经过充分的实验验证和优化。可能存在一些更合适的提示设计方法，比如使用不同长度或不同位置的提示，或者使用动态或自适应的提示。
- **零初始化注意力的选择**：这个模型提出了一种零初始化注意力机制，用于控制适配提示在注意力分数中的重要性。这种机制通过一个可学习的门控因子来实现，它可以在训练过程中逐渐增加适配提示对模型输出的影响。然而，这种机制也可能存在一些缺点，比如可能导致模型对适配提示过度依赖或忽略原始文本标记，或者可能导致门控因子难以收敛或过拟合。可能存在一些更好的注意力机制，比如使用其他类型的门控函数或其他方式来平衡适配提示和文本标记的贡献。





# LLaMa介绍

## LLaMa是什么
LLaMA（Large Language Model Meta AI）是一种大型语言模型（LLMs），由Meta AI于2023年2月发布。在LLaMa的第一个版本中，训练了四种模型大小：7、13、33和65亿个参数。它旨在帮助研究人员在人工智能的这个子领域推进他们的工作。

## LLaMa应用场景
LLaMA（Large Language Model Meta AI）是一种大型语言模型，它具有多种应用场景。例如，它可以生成创造性文本，解决数学定理，预测蛋白质结构，回答阅读理解问题等。作为一种基础模型，LLaMA被设计成多功能的，可以应用于许多不同的用例，而不是针对特定任务设计的微调模型1。此外，Meta公司还发布了LLaMA 2，它包括7B、13B和70B模型，并且在更多令牌上进行了训练。这些模型不仅进一步加速了大型语言模型的研究工作，还使企业能够构建自己的生成性人工智能应用程序。

## LLaMa的性能

- **高效的适配**：这个模型只需要1.2M个可学习的参数和一个小时的训练，就可以将LLaMA转化为一个能够根据指令生成响应的语言模型。相比于全微调的7B参数的Alpaca，这个模型具有优越的效率。
- **零初始化注意力**：为了提高训练的稳定性和最终的性能，这个模型提出了一种零初始化注意力机制，可以自适应地将指令信号注入到LLaMA中，同时有效地保留了LLaMA的预训练生成知识。
- **多模态推理**：这个模型不仅限于文本指令，还可以扩展到图像条件下的多模态推理，在ScienceQA基准上表现出竞争性的性能。





# LLaMA-Adapter

## 介绍
LLaMA-Adapter是一种轻量级的适配方法，用于高效地微调LLaMA，使其成为一个能够根据指令生成响应的语言模型。它只需要1.2M个可学习的参数和一个小时的训练，就可以有效地微调LLaMA，并且与全微调的7B参数的Alpaca相比具有优越的效率。

## 机制
LLaMA-Adapter采用了一组可学习的适配提示，并在更高的变压器层中将它们添加到输入文本标记中。这些提示学会了如何自适应地将新指令（条件）注入到LLaMA中。为了避免在早期训练阶段适配提示带来的噪声，我们修改了插入层处的香草注意力机制，使其成为零初始化注意力，具有可学习的门控因子。通过零向量初始化，门控可以首先保留LLaMA中原有的知识，并在训练过程中逐渐合并指令信号。这有助于在微调过程中稳定学习，并更好地提高最终模型的指令跟随能力。

## 特征
- **1.2M参数**：我们冻结预训练的LLaMA，只在顶部学习1.2M个参数的适配提示。然而，这揭示了与7B Alpaca相当的指令跟随能力。
- **一小时微调**：由于轻量级参数和我们的零初始化门控，LLaMA-Adapter的收敛成本不到8个A100 GPU上的一个小时，比Alpaca快三倍。
- **插入专业知识**：对于不同的场景，可以灵活地插入各自的适配器并赋予LLaMA不同的专业知识。因此，在每个上下文中存储1.2M适配器就足够了，而不是完整复制7B模型。
- **多模态条件**：除了文本指令外，LLaMA-Adapter还可以扩展到图像输入以进行多模态推理。通过简单地将图像标记添加到适配提示中，LLaMA-Adapter在ScienceQA基准测试中表现出优越的推理能力。










# 疑难解答

## 零初始化注意力
零初始化注意力是一种注意力机制，它可以自适应地将指令信号注入到LLaMA中，同时有效地保留了LLaMA的预训练生成知识。这种机制通过使用一个可学习的门控因子来控制注意力分数，从而在训练的早期阶段避免了由于随机初始化而引入的干扰。这种机制的目的是在保持训练稳定性和最终性能的同时，将新的指令信号注入到模型中。

## 门控因子
门控因子是一种可学习的参数，用于控制注意力分数中适配提示的重要性。它通过乘以适配提示的注意力分数来实现这一点。在训练的早期阶段，门控因子被初始化为零，这意味着适配提示对模型的输出没有影响。随着训练的进行，门控因子的值会逐渐增加，从而允许适配提示对模型的输出产生更大的影响。这种机制可以有效地避免在训练早期由于随机初始化而引入的干扰，从而提高模型的训练稳定性和最终性能。

