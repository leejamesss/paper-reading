![image](https://github.com/leejamesss/paper-reading/assets/117844938/ef80ed24-94ec-48f5-8b73-056b561f0afb)

![image](https://github.com/leejamesss/paper-reading/assets/117844938/18983e71-b318-4f91-ac7c-e50c2a949eee)

![image](https://github.com/leejamesss/paper-reading/assets/117844938/15eb66a6-be85-4938-9f57-cb2d33022bde)

# 1. 这篇论文的主要贡献是什么？
- **提出了OREOLM模型**，这是一种将符号知识图推理与现有语言模型结合的新颖模型架构。与以前的工作不同，OREOLM可以无缝地插入现有的语言模型中，实现知识图与语言模型的深度交互。
- **使用RoBERTa和T5预训练了OREOLM**，并在维基百科语料库上进行了预训练。OREOLM可以在开放域问答方面带来显著的性能提升，尤其是对于需要多跳推理的复杂问题。
- **OREOLM提供了可解释的推理路径**，用于回答问题，并总结了一般的关系规则作为推理的依据。
  
- **知识交互层**：这是OREOLM的核心组件，它可以灵活地插入到任何基于Transformer的语言模型中，实现与知识图谱推理模块的协同交互。在这个层面上，语言模型可以指导知识图谱沿着相关的关系进行随机游走，从而检索出与问题有关的实体，而检索到的知识又可以反过来改善语言模型的表示。
- **知识图谱推理模块**：这是OREOLM的另一个重要组件，它可以维护不同的推理路径，每个路径都从问题中的一个实体开始，沿着知识图谱进行多步推理，从而获取更多的外部知识。这个模块采用了一种可微分的上下文相关的随机游走算法，可以在端到端的方式下进行训练和推理。
- **预训练目标**：为了让OREOLM能够有效地利用知识图谱，作者设计了三个自监督的预训练目标，分别是实体跨度掩码、实体链接损失和关系预测损失。这些目标可以帮助OREOLM学习更好的实体和关系的表示，以及如何在知识图谱上进行推理。

PS.实体链接损失（Entity Linking Loss）是一种在自然语言处理（NLP）和知识图谱构建过程中，用于衡量实体识别和链接效果的指标。它主要用于评价模型在处理文本时，将实体识别出来并与知识图谱中的实体进行正确链接的能力。实体链接损失通常采用交叉熵损失（Cross-Entropy Loss）或其他适用于实体识别与链接的损失函数。实体链接损失的主要目标是提高模型在处理自然语言文本时，对实体进行准确识别和链接的能力，从而更好地构建知识图谱。实体链接损失可以帮助提高信息抽取、关系抽取、问答系统等任务的性能。

PS.关系预测损失是一种用于衡量预测结果与实际关系之间差异的指标。在自然语言处理、推荐系统等任务中，关系预测损失可以帮助模型学习到正确的实体间关联。简而言之，它就是预测一个实体与另一个实体之间是否存在关系的损失。

在实际应用中，关系预测损失通常使用基于梯度下降的优化算法进行优化，以最小化预测损失函数。这可以通过计算预测关系与实际关系之间的相似度来实现，例如使用余弦相似度、Jaccard相似度等。

eg.在一个推荐系统中，模型需要预测用户与物品之间的关系。关系预测损失可以表示为：

$$
\mathcal{L} = -\frac{1}{N} \sum_{u, i} y_{ui} \log(\hat{y}_{ui}) + (1 - y_{ui}) \log(1 - \hat{y}_{ui})
$$

其中，$N$ 是样本数量，$y_{ui}$ 表示用户 $u$ 与物品 $i$ 之间是否存在关系的真实标签，$\hat{y}_{ui}$ 是模型预测的关系概率。这个损失函数鼓励模型最大化正确预测的关系（$y_{ui}=1$）并最小化错误预测的关系（$y_{ui}=0$）。


PS.实体跨度掩码（Entity Span Mask）是一种在自然语言处理（NLP）和文本挖掘任务中使用的技术，用于识别和定位文本中的实体。实体跨度掩码通过对文本序列进行掩码，隐藏实体边界信息，从而在一定程度上减少噪声对实体识别任务的影响。实体跨度掩码有助于更准确地识别和分割文本中的实体。在实际应用中，如命名实体识别（NER）等任务，实体跨度掩码可以帮助模型专注于识别实体的起始和结束位置，提高识别准确性。

# 2. 这个贡献重要吗？为什么？

1. **模型创新**：OREOLM模型是一种新颖的模型架构，它将符号知识图推理与现有语言模型结合起来。这种结合方式可以实现知识图与语言模型的深度交互，这是以前的工作无法做到的。

2. **性能提升**：OREOLM模型在开放域问答方面带来了显著的性能提升，尤其是对于需要多跳推理的复杂问题。这意味着该模型能够更好地理解和回答复杂的问题，提高了模型的实用性。

3. **可解释性**：OREOLM模型提供了可解释的推理路径，这对于理解模型的决策过程非常有帮助。此外，它还总结了一般的关系规则作为推理的依据，这有助于我们理解模型是如何进行推理的。


# 3. 这篇论文的局限是什么？

- **推理步数有限**：作者在实验中发现，使用两步推理比一步推理有更好的性能，但是当推理步数增加到三步时，性能并没有提升。作者认为可能的原因是知识图谱中存在大量的缺失关系，以及不同层次的表示空间不一致。因此，如何训练模型进行更多步的推理，支持逻辑推理等，仍然是一个挑战。
- **实体嵌入表过大，需要预训练和GPU资源**：作者的模型设计需要一个巨大的实体嵌入表，这个表不能直接在下游任务上微调，而需要额外的监督信号和预训练。这限制了模型的使用场景和效率。
- **需要实体链接**：作者的模型设计需要一个额外的实体链接步骤，来识别问题中的实体，并用特殊的标记作为接口。一个真正的端到端的模型应该能够自己识别哪些元素需要进行推理，而不依赖于外部的模型。
- **只支持基于路径的关系推理**：虽然有很多潜在的推理任务，如逻辑推理，常识推理，物理推理，时间推理等，作者的模型设计主要关注基于路径的关系推理，而不能处理其他类型的推理任务。
- **不合理的路径独立性假设**：作者在推导公式1时，假设了从不同实体开始的推理路径是独立的。这并不总是正确的，特别是对于需要逻辑推理的问题，比如有并联或交叉操作的每个实体状态。因此，作者的模型可能不适用于那些有逻辑依赖的复杂问题。

# 4. 根据这篇文章的结果，你得到什么启发？

- **OREOLM是一种新颖的模型，可以将符号知识图推理与现有的语言模型结合起来。**这种模型可以在语言模型的中间层插入知识交互层，与一个可微分的知识图推理模块协作，从而实现从问题中提取的实体出发，沿着知识图进行多步推理，获取相关的知识，并将其注入语言模型中。
- **OREOLM可以显著提高开放域问答的性能，无论是闭书还是开书的设置，也无论是编码器还是编码器-解码器的模型。**在多个单跳和多跳的问答数据集上，OREOLM都能超过现有的基线模型，甚至能与一些专门为开书问答设计的模型相媲美。OREOLM还可以生成推理路径，帮助解释模型的预测。
- **OREOLM具有较好的可解释性和泛化性。**OREOLM不仅可以为每个问题提供一个推理路径作为理由，还可以总结出一些高阶的推理规则来推断缺失的关系。这些规则可以帮助模型在没有进一步微调的情况下，转移到其他的问答数据集上。OREOLM还可以利用知识图的结构性，支持逻辑推理和推理缺失的知识。



# 5. 这篇论文的研究假设是什么？这些假设是否合理、局限或过于简化？
这篇论文的研究假设是：

- 通过将知识图谱推理与语言模型相结合，可以提高闭域问答的性能和可解释性。
- 通过在语言模型中插入知识交互层，可以实现与知识图谱推理模块的灵活协作。
- 通过在无标注的维基百科语料库上进行预训练，可以学习更好的实体和关系表示以及如何在它们之间进行推理。


- 合理性:因为它们基于现有的研究工作，并且在实验中得到了验证。这篇论文展示了OREOLM在多个问答数据集上的优越性能，以及它能够生成有意义的推理路径作为解释。
- 局限性:，因为它们只考虑了基于知识图谱的推理，而没有涉及其他类型的推理，如逻辑推理、常识推理、物理推理、时间推理等。这篇论文没有探索OREOLM在这些复杂的问答任务上的表现，也没有比较不同的知识图谱来源和质量对结果的影响。
- 简化性：忽略了一些实际的挑战，如实体链接的错误、知识图谱的不完整性、推理路径的依赖性、语言模型的泛化能力等。这篇论文没有充分讨论这些问题对OREOLM的影响，也没有提出有效的解决方案。

# 6. 基于这篇论文的可能应用有哪些？

- **基于知识图谱的问答系统**：这篇论文提出了一种将知识图谱推理与语言模型结合的方法，可以有效地利用知识图谱中的结构化知识来回答开放域的问题。这种方法可以应用于构建基于知识图谱的问答系统，提高问答的准确性和可解释性。例如，可以使用这种方法来回答一些需要多跳推理或缺失关系的问题，如“巴黎是哪个国家的首都？”或“谁是美国第一任总统的妻子？”。
- **知识图谱的补全和推理**：这篇论文提出了一种利用语言模型的预训练和微调来学习实体和关系的表示，以及如何在知识图谱上进行推理的方法。这种方法可以应用于知识图谱的补全和推理，通过语言模型的语义理解和知识图谱的逻辑推理，来发现和填补知识图谱中的缺失或错误的信息。例如，可以使用这种方法来推断一些隐含或未知的关系，如“哪些国家的首都位于欧洲？”或“哪些作家的作品被改编成了电影？”。
- **知识图谱的可视化和解释**：这篇论文提出了一种利用知识图谱的推理路径来解释语言模型的预测的方法，可以提高语言模型的可解释性和可信度。这种方法可以应用于知识图谱的可视化和解释，通过展示语言模型如何利用知识图谱中的实体和关系来回答问题，以及给出推理的证据和规则，来增强用户对语言模型的理解和信任。例如，可以使用这种方法来生成一些图形或文本的可视化，来展示语言模型的推理过程和结果，如“为什么巴黎是法国的首都？”或“如何从知识图谱中推断出美国第一任总统的妻子是谁？”。

# 7. 在该文基础上，有些工作可以继续延伸下去？如何延伸？


- **探索更多的知识图谱推理方法**。文章中使用的是基于随机游走的知识图谱推理模块，但是这种方法可能存在一些局限性，比如无法处理逻辑推理、常识推理等复杂的推理任务。可以尝试使用其他的知识图谱推理方法，比如基于图神经网络的推理方法，或者基于符号逻辑的推理方法，来提高模型的推理能力和泛化能力。
- **探索更多的知识图谱来源和结构**。文章中使用的是WikiData作为知识图谱的来源，但是WikiData可能并不包含所有的领域知识和实体关系。可以尝试使用其他的知识图谱来源，比如FreeBase、ConceptNet等，或者结合多个知识图谱来源，来增加模型的知识覆盖度和多样性。另外，也可以探索使用不同的知识图谱结构，比如基于超图的知识图谱，或者基于属性的知识图谱，来更好地表示知识的复杂性和多维性。
- **探索更多的知识交互层的设计和位置**。文章中使用的是在语言模型的中间层插入知识交互层，来实现语言模型和知识图谱推理模块的交互。但是这种设计可能并不是最优的，因为语言模型的不同层可能有不同的语义表示和功能。可以尝试使用不同的知识交互层的设计，比如基于注意力机制的交互层，或者基于门控机制的交互层，来更有效地融合语言模型和知识图谱的信息。另外，也可以探索在语言模型的不同位置插入知识交互层，比如在语言模型的输入层、输出层，或者多个层，来分析不同位置的交互层对模型性能的影响。

# 8. 这篇论文中，哪些是你还没明白的地方？


这篇论文中，我还没有明白的地方有：

- **实验设置**：这篇论文的实验部分涉及了多个不同的问答数据集和评估指标，但是没有给出具体的实验细节，比如数据集的划分、模型的超参数、训练的时间和资源等。这些信息对于复现和比较这篇论文的结果是非常重要的。
- **理论分析**：这篇论文的理论部分主要是介绍了OREOLM的模型结构和预训练目标，但是没有给出OREOLM的理论保证，比如它的收敛性、泛化性、可解释性等。这些分析对于理解OREOLM的优势和局限性是非常有帮助的。
- **与其他方法的对比**：这篇论文的相关工作部分主要是介绍了一些使用知识图谱或语言模型的问答方法，但是没有给出OREOLM与这些方法的详细对比，比如它们的异同点、优缺点、适用场景等。这些对比对于展示OREOLM的创新性和有效性是非常有意义的。

# 9. 基于这篇论文的思想，若要做一个项目，能否用两句话描述一下这个项目的大致思想？

- 利用OREOLM模型，构建一个基于知识图谱推理的问答系统，可以回答开放领域的问题，同时提供推理路径作为解释。
- 该系统首先利用实体链接技术，从问题中识别出相关的实体，然后利用知识图谱中的三元组，进行多步推理，找到与问题相关的知识，最后生成答案和推理路径。
